# 第17课：决策树——告诉你 Hello Kitty 是人是猫

**决策树算法特点：**

* 优点：计算复杂度不高，输出结果易于理解，数据有缺失也能跑，可以处理不相关特征。

* 缺点：容易过拟合。

* 适用数据类型：数值型和标称型。

* 和逻辑回归比，逻辑回归可以告诉我们概率，而决策树只能0 ，1

* 停止条件： 

  1.达到预定的深度 

  2.节点内样本数量足够少  

**CART 回归树,每次计算mse，谁的最好，留谁**

**单颗决策树的缺点：** 

* 1.运算量大，需要一次加载所有数据进内存。并且找寻分割条件是一个极耗资源的工作 

* 2.训练样本中出现异常数据时，将会对决策树产生很大影响，抗干扰能力差 

**解决办法： **

* 1.减少决策树所需的训练样本 
* 2.随机采样，降低异常数据的影响 

**决策树优化**

* 预剪枝/先剪枝（局部剪枝）：在构造过程中，当某个节点满足剪枝条件，则直接停止此分支的构造。
* 后剪枝（全局剪枝）：先构造完成完整的决策树，再通过某些条件遍历树进行剪枝。